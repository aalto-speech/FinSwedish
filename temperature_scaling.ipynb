{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa53007-47b1-41ff-8eec-95842f0d0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import json\n",
    "import torchaudio\n",
    "\n",
    "import utils.myutils as myutils\n",
    "\n",
    "pio.renderers.default = \"jupyterlab\" # use \"jupyterlab\" for jupyterlab or \"\"notebook_connected\" for jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598581a-78d1-4658-bc62-2d0526f95913",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## SET UP PARAMETERS ###############################################\n",
    "SAMPLING_RATE = 16000\n",
    "PATH_MODEL = \"PATH_TO_MODEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7833b3-93f4-440d-bc68-3af4ebc253f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringEdit(listText, isPhoneme=False):\n",
    "    # Edit test transcript to remove unwanted characters:\n",
    "    tempList = []\n",
    "    for text in listText:\n",
    "        #text = text.upper()\n",
    "        text = text.replace('\\n', ' ')        \n",
    "        text = text.replace('-', ' ')\n",
    "        text = text.replace('\\'', ' ')        \n",
    " \n",
    "        text = \" \".join(text.split())\n",
    "        text = text.replace(' ', '|')        \n",
    "        tempList.append(text)\n",
    "    return tempList\n",
    "\n",
    "transcript = 'TRANSCRIPT'\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(PATH_MODEL)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(PATH_MODEL)\n",
    "\n",
    "transcript = stringEdit([transcript])[0]\n",
    "\n",
    "transcript = \" \".join(transcript.split())\n",
    "print(f\"Transcript {transcript}\")\n",
    "\n",
    "transcript = transcript.replace(' ', '|')                  \n",
    "\n",
    "# Load vocab file:\n",
    "with open(PATH_MODEL + '/vocab.json', encoding='utf-8') as json_file:\n",
    "    vocab = json.load(json_file)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    waveform, sr = torchaudio.load('PATH_TO_AUDIO_FILE')\n",
    "\n",
    "# transpose to match dimension with Wav2Vec2 processor\n",
    "input_audio = torch.transpose(waveform, 1,0)\n",
    "\n",
    "# indexing to get only 1 channel (incase the recording are from 2 channels)\n",
    "input_audio = input_audio[:, 0]                       \n",
    "\n",
    "input_values = processor(input_audio, sampling_rate=SAMPLING_RATE, return_tensors=\"pt\").input_values\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "prediction = processor.batch_decode(predicted_ids)\n",
    "print(f\"Prediction {prediction}\")\n",
    "\n",
    "tokens = [vocab[c] for c in transcript]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a92be3-32e0-42b0-a052-fe657c0c3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_scaling(logits, temperature):\n",
    "    \"\"\"\n",
    "    Apply temperature scaling to logits.\n",
    "    \n",
    "    :param logits: torch tensor of logits\n",
    "    :param temperature: temperature factor\n",
    "    :return: scaled logits\n",
    "    \"\"\"\n",
    "    return logits / temperature\n",
    "\n",
    "def topk_normalize(probabilities, topk = 3):\n",
    "    \"\"\"\n",
    "    Normalize the top-k probabilities in a tensor while keeping the rest unchanged.\n",
    "\n",
    "    :param probabilities: The input tensor.\n",
    "    :param topk: The number of top elements to consider.\n",
    "    :return: A tensor of the same size as the input, but with only the top-k elements \n",
    "    normalized to sum to 1, and the rest left as they were.\n",
    "    \"\"\"\n",
    "    # Compute the highest value and its index\n",
    "    # Only use the higest - k = 1\n",
    "    top_values, top_indices = torch.topk(probabilities, 1)        \n",
    "    \n",
    "    top_values_norm, top_indices_norm = torch.topk(probabilities, topk)\n",
    "    bottom_values, bottom_indice = torch.topk(probabilities, probabilities.shape[-1] - topk, largest=False)\n",
    "\n",
    "    top_prob_normalized = top_values_norm / top_values \n",
    "\n",
    "    # Generate the new probability tensor where only topk_norm items are normalized\n",
    "    new_probabilities = torch.zeros_like(probabilities)\n",
    "\n",
    "    # Scatter the normalized top-k values into the result tensor\n",
    "    new_probabilities.scatter_(-1, top_indices_norm, top_prob_normalized)\n",
    "\n",
    "    # Scatter the untouched bottom probabilities\n",
    "    new_probabilities.scatter_(-1, bottom_indice, bottom_values)    \n",
    "    \n",
    "    return new_probabilities\n",
    "\n",
    "temperature = 10\n",
    "topk = 3\n",
    "\n",
    "# Apply temperature scaling with a factor of temperature\n",
    "scaled_logits = temperature_scaling(logits, temperature)\n",
    "\n",
    "# Compute probabilities using softmax\n",
    "scaled_probabilities = torch.nn.functional.softmax(scaled_logits, dim=-1)\n",
    "\n",
    "# Normalize the top-k probabilities\n",
    "emission = topk_normalize(scaled_probabilities, topk=topk)[0]\n",
    "emission = torch.log(emission)\n",
    "\n",
    "vocab_sort = dict(sorted(vocab.items(), key=lambda item: item[1]))\n",
    "list_token = [k for k,v in vocab_sort.items()]\n",
    "\n",
    "fig = px.imshow(emission.T.exp(), y=list_token, color_continuous_scale='viridis', height=1200)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
